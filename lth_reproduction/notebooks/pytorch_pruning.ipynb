{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pruning Demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../src/')\n",
    "\n",
    "from models import LeNetFC \n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LeNetFC().to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inspect a module"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[('weight', Parameter containing:\n",
      "tensor([[-0.0072,  0.0125, -0.0114,  ...,  0.0336, -0.0078,  0.0305],\n",
      "        [ 0.0037,  0.0083, -0.0224,  ...,  0.0031,  0.0111,  0.0004],\n",
      "        [ 0.0186, -0.0054,  0.0023,  ...,  0.0094, -0.0224, -0.0021],\n",
      "        ...,\n",
      "        [-0.0325,  0.0182,  0.0283,  ...,  0.0329,  0.0241, -0.0234],\n",
      "        [ 0.0230, -0.0012, -0.0095,  ...,  0.0044, -0.0146, -0.0155],\n",
      "        [ 0.0194,  0.0081, -0.0092,  ..., -0.0185, -0.0040, -0.0191]],\n",
      "       requires_grad=True)), ('bias', Parameter containing:\n",
      "tensor([-3.1015e-02,  2.3865e-02,  2.6890e-02, -3.1784e-02,  3.0637e-03,\n",
      "         3.9912e-03,  1.5114e-02,  2.7278e-02, -9.3997e-03, -8.3075e-03,\n",
      "        -2.4223e-03, -1.0882e-02, -2.8613e-02,  2.5166e-02,  1.3207e-02,\n",
      "         2.3371e-02,  1.8772e-03,  2.6723e-02, -2.3492e-02,  3.3078e-02,\n",
      "         1.8470e-02, -1.8554e-02, -1.8562e-02,  5.0716e-03,  3.5132e-02,\n",
      "        -1.9280e-02,  1.1390e-02,  3.0036e-02, -1.6311e-02,  3.2229e-02,\n",
      "        -7.9022e-03, -2.8195e-02, -1.6045e-02,  1.3871e-02, -2.2369e-02,\n",
      "        -3.3504e-02, -2.4561e-02, -1.6374e-02,  3.5233e-02, -4.5098e-05,\n",
      "         6.7201e-03,  1.9802e-02, -1.6798e-02, -1.2335e-02,  3.0768e-02,\n",
      "         3.4513e-02, -3.5322e-02,  3.4995e-02,  3.0114e-02,  2.7532e-02,\n",
      "         3.5117e-02,  1.5556e-02,  2.8822e-02, -3.3293e-02,  2.9663e-02,\n",
      "         3.2442e-02, -3.3936e-02, -2.2825e-03,  3.2091e-02,  1.6858e-02,\n",
      "        -2.0654e-02,  2.7805e-03, -3.4359e-02, -1.0304e-02, -2.2959e-02,\n",
      "        -1.4460e-03,  1.4745e-02,  3.0757e-03, -1.8319e-02,  2.9364e-02,\n",
      "        -2.8952e-02,  1.8799e-02,  2.5554e-02, -6.4329e-03, -1.0233e-02,\n",
      "         2.7704e-02,  9.2009e-03,  2.0041e-03, -1.8387e-02,  6.8755e-03,\n",
      "         1.2394e-02, -1.8421e-02,  2.8168e-02,  3.3484e-02, -2.2571e-02,\n",
      "        -1.1267e-02, -1.6488e-02,  2.2943e-02, -1.4450e-02,  5.2235e-03,\n",
      "         2.5782e-02, -3.2175e-02, -5.5981e-03, -2.3430e-02,  3.0283e-02,\n",
      "         2.3597e-02, -6.4177e-03,  1.4214e-03, -3.0088e-02,  3.5560e-02,\n",
      "         2.4460e-02,  7.3589e-04,  1.9315e-02, -3.1454e-02,  5.6516e-03,\n",
      "        -2.8515e-02, -9.6554e-03,  1.8887e-02, -2.1609e-02,  1.4044e-02,\n",
      "         2.9095e-03, -7.5098e-03, -1.3368e-02,  1.8876e-02, -1.2337e-02,\n",
      "        -5.7728e-03, -3.5665e-02, -1.5961e-02, -6.9260e-03, -4.5691e-03,\n",
      "        -2.0579e-02,  1.4815e-02,  2.2870e-02, -1.6639e-02,  2.5838e-02,\n",
      "        -4.3669e-03,  1.7423e-02, -1.0947e-02, -7.2512e-03,  1.0442e-02,\n",
      "        -2.9955e-02, -3.4292e-02,  3.0049e-02,  2.3229e-02,  2.1871e-02,\n",
      "         2.8857e-02, -2.9131e-02,  2.4932e-02,  2.7583e-02,  2.6843e-02,\n",
      "        -2.0982e-02, -2.2543e-02, -2.8851e-02, -2.4968e-02, -3.1817e-02,\n",
      "         6.9972e-03,  1.5601e-02,  2.2761e-02,  2.3245e-02, -2.2572e-02,\n",
      "        -1.0964e-02, -4.4762e-03,  1.0803e-02, -5.5370e-03, -2.4951e-02,\n",
      "         2.4942e-02, -6.9336e-03,  1.0830e-02, -1.7508e-02, -7.6402e-03,\n",
      "         4.9085e-04, -6.5144e-03, -1.6425e-02,  1.1883e-02,  3.9655e-03,\n",
      "         2.0174e-02,  2.6297e-02,  2.8287e-02, -1.1970e-03,  1.1331e-02,\n",
      "        -2.0810e-03,  1.6321e-02,  2.0727e-02, -9.5041e-03,  3.0908e-02,\n",
      "        -1.4816e-02, -2.1843e-02, -1.6491e-02, -1.7494e-02,  5.4043e-03,\n",
      "         1.3730e-02,  1.3074e-02,  2.4023e-02,  1.5521e-02,  2.6222e-02,\n",
      "        -1.8708e-02, -1.9519e-02,  3.0749e-02,  1.5525e-02,  2.2434e-02,\n",
      "        -3.0177e-02,  2.7785e-02, -3.0119e-02,  7.8024e-03,  1.0435e-02,\n",
      "         3.3130e-02,  3.1478e-02,  3.9991e-03,  3.3354e-02,  7.9081e-03,\n",
      "        -2.7737e-02,  8.4453e-03, -7.9397e-03, -2.4020e-02,  1.4844e-02,\n",
      "        -1.0712e-02,  5.6880e-03,  1.6308e-02, -1.6111e-02,  2.7626e-02,\n",
      "         9.3738e-03, -3.2654e-02,  4.7030e-03,  1.0237e-02, -1.8198e-02,\n",
      "         1.9119e-02,  7.3673e-03,  2.0546e-02,  3.2700e-02,  1.3907e-02,\n",
      "        -1.7440e-02,  4.6018e-03, -1.2999e-02, -3.4316e-03, -2.4018e-04,\n",
      "         1.2015e-02, -3.1257e-02, -1.8316e-03, -3.3754e-02,  3.0950e-02,\n",
      "        -1.5593e-02, -2.7830e-02, -7.9983e-03, -1.6681e-02, -3.4045e-02,\n",
      "         3.0619e-02,  1.4509e-02,  1.5502e-02,  1.8466e-02,  1.7578e-03,\n",
      "        -3.0244e-02, -2.6112e-02,  2.3248e-02, -1.8158e-02,  4.1169e-03,\n",
      "         2.0803e-02, -2.8405e-03,  1.2704e-02, -2.7347e-02, -2.0926e-02,\n",
      "         1.0059e-02,  1.6285e-02,  3.3451e-02,  3.2239e-03, -9.2612e-03,\n",
      "        -1.9314e-02, -1.1868e-02, -3.2789e-02, -1.7783e-02,  3.5461e-03,\n",
      "         2.2204e-02,  1.8026e-02, -1.1644e-02,  1.6536e-02,  5.3280e-03,\n",
      "         1.6212e-02, -3.5153e-02,  8.5781e-03,  1.9909e-02,  3.1554e-02,\n",
      "        -8.0358e-03,  1.5043e-02,  2.1724e-02,  6.4531e-03,  1.5447e-02,\n",
      "         7.8620e-03, -6.6004e-03,  4.7588e-03, -7.3986e-03,  2.8119e-02,\n",
      "        -5.5052e-03, -4.8317e-03,  3.2061e-02,  1.1363e-02, -1.0252e-02,\n",
      "        -1.8506e-02, -2.6599e-02, -1.7823e-02,  1.6339e-02,  1.3469e-02,\n",
      "         1.4306e-02,  3.5180e-02,  1.6782e-02, -3.1034e-02,  1.5737e-02,\n",
      "         2.3549e-02, -2.5455e-02,  1.8228e-03,  2.8863e-02, -1.9226e-02],\n",
      "       requires_grad=True))]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "module = model.fc1\n",
    "print(list(module.named_parameters()))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Linear(in_features=784, out_features=300, bias=True)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ],
   "source": [
    "# prune the weights (not biases here)\n",
    "p = 0.3\n",
    "prune.random_unstructured(module, name='weight', amount=p)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[('bias', Parameter containing:\n",
      "tensor([ 0.0208,  0.0041, -0.0104, -0.0334,  0.0135, -0.0234, -0.0034, -0.0069,\n",
      "        -0.0122,  0.0261,  0.0019,  0.0091, -0.0218,  0.0020, -0.0077,  0.0352,\n",
      "         0.0352,  0.0292, -0.0031, -0.0191, -0.0020,  0.0271,  0.0223, -0.0271,\n",
      "        -0.0354,  0.0079, -0.0193, -0.0305, -0.0163,  0.0302, -0.0009, -0.0099,\n",
      "        -0.0023,  0.0276,  0.0137,  0.0104, -0.0131, -0.0293,  0.0302, -0.0299,\n",
      "        -0.0143,  0.0234, -0.0095,  0.0079, -0.0148,  0.0045, -0.0010,  0.0357,\n",
      "        -0.0239, -0.0020,  0.0252,  0.0020, -0.0008, -0.0265,  0.0161, -0.0172,\n",
      "        -0.0338,  0.0101,  0.0002, -0.0014, -0.0280,  0.0115,  0.0237, -0.0202,\n",
      "        -0.0197,  0.0016,  0.0285, -0.0100, -0.0252,  0.0166, -0.0026,  0.0219,\n",
      "        -0.0257, -0.0307,  0.0342,  0.0321,  0.0306, -0.0112, -0.0102, -0.0183,\n",
      "        -0.0088, -0.0322,  0.0121,  0.0078,  0.0011,  0.0281,  0.0172, -0.0124,\n",
      "         0.0080, -0.0259, -0.0216,  0.0236, -0.0061,  0.0152,  0.0257,  0.0233,\n",
      "        -0.0134,  0.0185,  0.0297, -0.0322,  0.0109,  0.0115, -0.0148,  0.0273,\n",
      "        -0.0097, -0.0163, -0.0025, -0.0180, -0.0058,  0.0277, -0.0156,  0.0013,\n",
      "         0.0016,  0.0322, -0.0070, -0.0189, -0.0071,  0.0247,  0.0100,  0.0315,\n",
      "         0.0236,  0.0131,  0.0132,  0.0331, -0.0254,  0.0127,  0.0293, -0.0226,\n",
      "        -0.0144,  0.0067,  0.0084,  0.0172, -0.0002,  0.0204, -0.0039,  0.0249,\n",
      "         0.0086, -0.0309, -0.0280, -0.0082, -0.0083, -0.0352, -0.0153,  0.0258,\n",
      "        -0.0045, -0.0301,  0.0195,  0.0126, -0.0309,  0.0213,  0.0221, -0.0135,\n",
      "        -0.0308,  0.0241, -0.0140,  0.0160, -0.0201,  0.0143,  0.0147,  0.0010,\n",
      "        -0.0104, -0.0163,  0.0312, -0.0102, -0.0250,  0.0161, -0.0333,  0.0282,\n",
      "        -0.0160, -0.0153, -0.0335,  0.0307, -0.0291,  0.0059,  0.0070,  0.0309,\n",
      "         0.0243, -0.0231,  0.0221,  0.0200,  0.0181,  0.0032,  0.0310,  0.0238,\n",
      "         0.0249,  0.0187, -0.0136, -0.0352,  0.0098,  0.0124, -0.0113,  0.0003,\n",
      "        -0.0309,  0.0044,  0.0228,  0.0319,  0.0281, -0.0348, -0.0258, -0.0183,\n",
      "         0.0183,  0.0008,  0.0139, -0.0327, -0.0323, -0.0096, -0.0322,  0.0003,\n",
      "        -0.0285, -0.0188, -0.0325,  0.0185,  0.0312,  0.0294, -0.0288,  0.0018,\n",
      "         0.0211, -0.0017,  0.0317, -0.0253,  0.0153, -0.0010, -0.0204,  0.0070,\n",
      "         0.0197, -0.0133, -0.0221,  0.0235, -0.0314,  0.0339,  0.0051, -0.0043,\n",
      "        -0.0055,  0.0307,  0.0312,  0.0130,  0.0186, -0.0107, -0.0147, -0.0111,\n",
      "        -0.0142, -0.0029,  0.0219, -0.0142,  0.0171, -0.0096,  0.0208,  0.0269,\n",
      "         0.0137, -0.0338,  0.0272, -0.0085, -0.0310, -0.0047,  0.0088, -0.0223,\n",
      "         0.0114, -0.0328, -0.0038, -0.0187, -0.0123,  0.0332, -0.0147,  0.0113,\n",
      "         0.0200,  0.0261, -0.0021, -0.0354, -0.0226,  0.0229,  0.0335,  0.0338,\n",
      "        -0.0280,  0.0349, -0.0133, -0.0243,  0.0170, -0.0008, -0.0324, -0.0055,\n",
      "        -0.0151, -0.0021, -0.0221,  0.0132,  0.0297,  0.0217, -0.0203,  0.0218,\n",
      "         0.0247,  0.0310,  0.0161,  0.0357, -0.0277,  0.0087,  0.0257,  0.0132,\n",
      "         0.0081, -0.0245, -0.0186,  0.0224], requires_grad=True)), ('weight_orig', Parameter containing:\n",
      "tensor([[ 0.0259, -0.0029, -0.0148,  ..., -0.0338, -0.0061, -0.0222],\n",
      "        [-0.0279,  0.0280,  0.0118,  ..., -0.0110,  0.0140, -0.0108],\n",
      "        [-0.0050,  0.0167, -0.0258,  ..., -0.0210, -0.0264,  0.0171],\n",
      "        ...,\n",
      "        [ 0.0336, -0.0113,  0.0214,  ..., -0.0060, -0.0026,  0.0189],\n",
      "        [-0.0337, -0.0168,  0.0072,  ..., -0.0021,  0.0215,  0.0010],\n",
      "        [-0.0235, -0.0148, -0.0253,  ...,  0.0350, -0.0245, -0.0002]],\n",
      "       requires_grad=True))]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# notice 'weight_orig' is stored, 'weight' now contains pruned params\n",
    "print(list(module.named_parameters()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[1., 0., 1.,  ..., 1., 1., 0.],\n",
      "        [1., 0., 0.,  ..., 1., 1., 1.]])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# see mask\n",
    "print(module.weight_mask[:2])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[ 0.0259, -0.0000, -0.0148,  ..., -0.0338, -0.0061, -0.0000],\n",
      "        [-0.0279,  0.0000,  0.0000,  ..., -0.0110,  0.0140, -0.0108]],\n",
      "       grad_fn=<SliceBackward>)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# see new pruned params (compare to weight_orig printed above, see how mask is applied?)\n",
    "print(module.weight[:2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Linear(in_features=784, out_features=300, bias=True)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "# remove 3 smallest bias params according to L1 norm\n",
    "prune.l1_unstructured(module, name=\"bias\", amount=3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[('weight_orig', Parameter containing:\n",
      "tensor([[ 0.0259, -0.0029, -0.0148,  ..., -0.0338, -0.0061, -0.0222],\n",
      "        [-0.0279,  0.0280,  0.0118,  ..., -0.0110,  0.0140, -0.0108],\n",
      "        [-0.0050,  0.0167, -0.0258,  ..., -0.0210, -0.0264,  0.0171],\n",
      "        ...,\n",
      "        [ 0.0336, -0.0113,  0.0214,  ..., -0.0060, -0.0026,  0.0189],\n",
      "        [-0.0337, -0.0168,  0.0072,  ..., -0.0021,  0.0215,  0.0010],\n",
      "        [-0.0235, -0.0148, -0.0253,  ...,  0.0350, -0.0245, -0.0002]],\n",
      "       requires_grad=True)), ('bias_orig', Parameter containing:\n",
      "tensor([ 0.0208,  0.0041, -0.0104, -0.0334,  0.0135, -0.0234, -0.0034, -0.0069,\n",
      "        -0.0122,  0.0261,  0.0019,  0.0091, -0.0218,  0.0020, -0.0077,  0.0352,\n",
      "         0.0352,  0.0292, -0.0031, -0.0191, -0.0020,  0.0271,  0.0223, -0.0271,\n",
      "        -0.0354,  0.0079, -0.0193, -0.0305, -0.0163,  0.0302, -0.0009, -0.0099,\n",
      "        -0.0023,  0.0276,  0.0137,  0.0104, -0.0131, -0.0293,  0.0302, -0.0299,\n",
      "        -0.0143,  0.0234, -0.0095,  0.0079, -0.0148,  0.0045, -0.0010,  0.0357,\n",
      "        -0.0239, -0.0020,  0.0252,  0.0020, -0.0008, -0.0265,  0.0161, -0.0172,\n",
      "        -0.0338,  0.0101,  0.0002, -0.0014, -0.0280,  0.0115,  0.0237, -0.0202,\n",
      "        -0.0197,  0.0016,  0.0285, -0.0100, -0.0252,  0.0166, -0.0026,  0.0219,\n",
      "        -0.0257, -0.0307,  0.0342,  0.0321,  0.0306, -0.0112, -0.0102, -0.0183,\n",
      "        -0.0088, -0.0322,  0.0121,  0.0078,  0.0011,  0.0281,  0.0172, -0.0124,\n",
      "         0.0080, -0.0259, -0.0216,  0.0236, -0.0061,  0.0152,  0.0257,  0.0233,\n",
      "        -0.0134,  0.0185,  0.0297, -0.0322,  0.0109,  0.0115, -0.0148,  0.0273,\n",
      "        -0.0097, -0.0163, -0.0025, -0.0180, -0.0058,  0.0277, -0.0156,  0.0013,\n",
      "         0.0016,  0.0322, -0.0070, -0.0189, -0.0071,  0.0247,  0.0100,  0.0315,\n",
      "         0.0236,  0.0131,  0.0132,  0.0331, -0.0254,  0.0127,  0.0293, -0.0226,\n",
      "        -0.0144,  0.0067,  0.0084,  0.0172, -0.0002,  0.0204, -0.0039,  0.0249,\n",
      "         0.0086, -0.0309, -0.0280, -0.0082, -0.0083, -0.0352, -0.0153,  0.0258,\n",
      "        -0.0045, -0.0301,  0.0195,  0.0126, -0.0309,  0.0213,  0.0221, -0.0135,\n",
      "        -0.0308,  0.0241, -0.0140,  0.0160, -0.0201,  0.0143,  0.0147,  0.0010,\n",
      "        -0.0104, -0.0163,  0.0312, -0.0102, -0.0250,  0.0161, -0.0333,  0.0282,\n",
      "        -0.0160, -0.0153, -0.0335,  0.0307, -0.0291,  0.0059,  0.0070,  0.0309,\n",
      "         0.0243, -0.0231,  0.0221,  0.0200,  0.0181,  0.0032,  0.0310,  0.0238,\n",
      "         0.0249,  0.0187, -0.0136, -0.0352,  0.0098,  0.0124, -0.0113,  0.0003,\n",
      "        -0.0309,  0.0044,  0.0228,  0.0319,  0.0281, -0.0348, -0.0258, -0.0183,\n",
      "         0.0183,  0.0008,  0.0139, -0.0327, -0.0323, -0.0096, -0.0322,  0.0003,\n",
      "        -0.0285, -0.0188, -0.0325,  0.0185,  0.0312,  0.0294, -0.0288,  0.0018,\n",
      "         0.0211, -0.0017,  0.0317, -0.0253,  0.0153, -0.0010, -0.0204,  0.0070,\n",
      "         0.0197, -0.0133, -0.0221,  0.0235, -0.0314,  0.0339,  0.0051, -0.0043,\n",
      "        -0.0055,  0.0307,  0.0312,  0.0130,  0.0186, -0.0107, -0.0147, -0.0111,\n",
      "        -0.0142, -0.0029,  0.0219, -0.0142,  0.0171, -0.0096,  0.0208,  0.0269,\n",
      "         0.0137, -0.0338,  0.0272, -0.0085, -0.0310, -0.0047,  0.0088, -0.0223,\n",
      "         0.0114, -0.0328, -0.0038, -0.0187, -0.0123,  0.0332, -0.0147,  0.0113,\n",
      "         0.0200,  0.0261, -0.0021, -0.0354, -0.0226,  0.0229,  0.0335,  0.0338,\n",
      "        -0.0280,  0.0349, -0.0133, -0.0243,  0.0170, -0.0008, -0.0324, -0.0055,\n",
      "        -0.0151, -0.0021, -0.0221,  0.0132,  0.0297,  0.0217, -0.0203,  0.0218,\n",
      "         0.0247,  0.0310,  0.0161,  0.0357, -0.0277,  0.0087,  0.0257,  0.0132,\n",
      "         0.0081, -0.0245, -0.0186,  0.0224], requires_grad=True))]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# note bias_orig\n",
    "print(list(module.named_parameters()))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Iterative Pruning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(2940.2478, grad_fn=<SumBackward0>)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 10
    }
   ],
   "source": [
    "# total magnitude of weights\n",
    "torch.sum(abs(module.weight))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Linear(in_features=784, out_features=300, bias=True)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 11
    }
   ],
   "source": [
    "prune.ln_structured(module, name='weight', amount=p+.2, n=2, dim=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1511.8176, grad_fn=<SumBackward0>)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 12
    }
   ],
   "source": [
    "# can see half the weights are now zeroed out (pruned/remove)\n",
    "torch.sum(abs(module.weight))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "<torch.nn.utils.prune.RandomUnstructured object at 0x7fae6835a590>\n",
      "<torch.nn.utils.prune.LnStructured object at 0x7faea8835490>\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# history of pruning applied to weight param\n",
    "for hook in module._forward_pre_hooks.values():\n",
    "    if hook._tensor_name == 'weight':\n",
    "        break\n",
    "\n",
    "for h in hook:\n",
    "    print(h)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "odict_keys(['fc1.weight_orig', 'fc1.bias_orig', 'fc1.weight_mask', 'fc1.bias_mask', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# serialized and retrievable \n",
    "print(model.state_dict().keys())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make Pruning Permanent\n",
    "Remove pruning re-parametrization.  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[('weight_orig', Parameter containing:\n",
      "tensor([[ 0.0259, -0.0029, -0.0148,  ..., -0.0338, -0.0061, -0.0222],\n",
      "        [-0.0279,  0.0280,  0.0118,  ..., -0.0110,  0.0140, -0.0108],\n",
      "        [-0.0050,  0.0167, -0.0258,  ..., -0.0210, -0.0264,  0.0171],\n",
      "        ...,\n",
      "        [ 0.0336, -0.0113,  0.0214,  ..., -0.0060, -0.0026,  0.0189],\n",
      "        [-0.0337, -0.0168,  0.0072,  ..., -0.0021,  0.0215,  0.0010],\n",
      "        [-0.0235, -0.0148, -0.0253,  ...,  0.0350, -0.0245, -0.0002]],\n",
      "       requires_grad=True)), ('bias_orig', Parameter containing:\n",
      "tensor([ 0.0208,  0.0041, -0.0104, -0.0334,  0.0135, -0.0234, -0.0034, -0.0069,\n",
      "        -0.0122,  0.0261,  0.0019,  0.0091, -0.0218,  0.0020, -0.0077,  0.0352,\n",
      "         0.0352,  0.0292, -0.0031, -0.0191, -0.0020,  0.0271,  0.0223, -0.0271,\n",
      "        -0.0354,  0.0079, -0.0193, -0.0305, -0.0163,  0.0302, -0.0009, -0.0099,\n",
      "        -0.0023,  0.0276,  0.0137,  0.0104, -0.0131, -0.0293,  0.0302, -0.0299,\n",
      "        -0.0143,  0.0234, -0.0095,  0.0079, -0.0148,  0.0045, -0.0010,  0.0357,\n",
      "        -0.0239, -0.0020,  0.0252,  0.0020, -0.0008, -0.0265,  0.0161, -0.0172,\n",
      "        -0.0338,  0.0101,  0.0002, -0.0014, -0.0280,  0.0115,  0.0237, -0.0202,\n",
      "        -0.0197,  0.0016,  0.0285, -0.0100, -0.0252,  0.0166, -0.0026,  0.0219,\n",
      "        -0.0257, -0.0307,  0.0342,  0.0321,  0.0306, -0.0112, -0.0102, -0.0183,\n",
      "        -0.0088, -0.0322,  0.0121,  0.0078,  0.0011,  0.0281,  0.0172, -0.0124,\n",
      "         0.0080, -0.0259, -0.0216,  0.0236, -0.0061,  0.0152,  0.0257,  0.0233,\n",
      "        -0.0134,  0.0185,  0.0297, -0.0322,  0.0109,  0.0115, -0.0148,  0.0273,\n",
      "        -0.0097, -0.0163, -0.0025, -0.0180, -0.0058,  0.0277, -0.0156,  0.0013,\n",
      "         0.0016,  0.0322, -0.0070, -0.0189, -0.0071,  0.0247,  0.0100,  0.0315,\n",
      "         0.0236,  0.0131,  0.0132,  0.0331, -0.0254,  0.0127,  0.0293, -0.0226,\n",
      "        -0.0144,  0.0067,  0.0084,  0.0172, -0.0002,  0.0204, -0.0039,  0.0249,\n",
      "         0.0086, -0.0309, -0.0280, -0.0082, -0.0083, -0.0352, -0.0153,  0.0258,\n",
      "        -0.0045, -0.0301,  0.0195,  0.0126, -0.0309,  0.0213,  0.0221, -0.0135,\n",
      "        -0.0308,  0.0241, -0.0140,  0.0160, -0.0201,  0.0143,  0.0147,  0.0010,\n",
      "        -0.0104, -0.0163,  0.0312, -0.0102, -0.0250,  0.0161, -0.0333,  0.0282,\n",
      "        -0.0160, -0.0153, -0.0335,  0.0307, -0.0291,  0.0059,  0.0070,  0.0309,\n",
      "         0.0243, -0.0231,  0.0221,  0.0200,  0.0181,  0.0032,  0.0310,  0.0238,\n",
      "         0.0249,  0.0187, -0.0136, -0.0352,  0.0098,  0.0124, -0.0113,  0.0003,\n",
      "        -0.0309,  0.0044,  0.0228,  0.0319,  0.0281, -0.0348, -0.0258, -0.0183,\n",
      "         0.0183,  0.0008,  0.0139, -0.0327, -0.0323, -0.0096, -0.0322,  0.0003,\n",
      "        -0.0285, -0.0188, -0.0325,  0.0185,  0.0312,  0.0294, -0.0288,  0.0018,\n",
      "         0.0211, -0.0017,  0.0317, -0.0253,  0.0153, -0.0010, -0.0204,  0.0070,\n",
      "         0.0197, -0.0133, -0.0221,  0.0235, -0.0314,  0.0339,  0.0051, -0.0043,\n",
      "        -0.0055,  0.0307,  0.0312,  0.0130,  0.0186, -0.0107, -0.0147, -0.0111,\n",
      "        -0.0142, -0.0029,  0.0219, -0.0142,  0.0171, -0.0096,  0.0208,  0.0269,\n",
      "         0.0137, -0.0338,  0.0272, -0.0085, -0.0310, -0.0047,  0.0088, -0.0223,\n",
      "         0.0114, -0.0328, -0.0038, -0.0187, -0.0123,  0.0332, -0.0147,  0.0113,\n",
      "         0.0200,  0.0261, -0.0021, -0.0354, -0.0226,  0.0229,  0.0335,  0.0338,\n",
      "        -0.0280,  0.0349, -0.0133, -0.0243,  0.0170, -0.0008, -0.0324, -0.0055,\n",
      "        -0.0151, -0.0021, -0.0221,  0.0132,  0.0297,  0.0217, -0.0203,  0.0218,\n",
      "         0.0247,  0.0310,  0.0161,  0.0357, -0.0277,  0.0087,  0.0257,  0.0132,\n",
      "         0.0081, -0.0245, -0.0186,  0.0224], requires_grad=True))]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Before: \n",
    "print(list(module.named_parameters()))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[('weight_mask', tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 1., 1., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 0.,  ..., 1., 0., 0.],\n",
      "        [1., 1., 0.,  ..., 1., 1., 0.]])), ('bias_mask', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Before: \n",
    "print(list(module.named_buffers()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[ 0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        [-0.0279,  0.0000,  0.0000,  ..., -0.0110,  0.0140, -0.0108],\n",
      "        [-0.0000,  0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "        [-0.0337, -0.0168,  0.0000,  ..., -0.0021,  0.0000,  0.0000],\n",
      "        [-0.0235, -0.0148, -0.0000,  ...,  0.0350, -0.0245, -0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Before\n",
    "print(module.weight)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[('bias_orig', Parameter containing:\n",
      "tensor([ 0.0208,  0.0041, -0.0104, -0.0334,  0.0135, -0.0234, -0.0034, -0.0069,\n",
      "        -0.0122,  0.0261,  0.0019,  0.0091, -0.0218,  0.0020, -0.0077,  0.0352,\n",
      "         0.0352,  0.0292, -0.0031, -0.0191, -0.0020,  0.0271,  0.0223, -0.0271,\n",
      "        -0.0354,  0.0079, -0.0193, -0.0305, -0.0163,  0.0302, -0.0009, -0.0099,\n",
      "        -0.0023,  0.0276,  0.0137,  0.0104, -0.0131, -0.0293,  0.0302, -0.0299,\n",
      "        -0.0143,  0.0234, -0.0095,  0.0079, -0.0148,  0.0045, -0.0010,  0.0357,\n",
      "        -0.0239, -0.0020,  0.0252,  0.0020, -0.0008, -0.0265,  0.0161, -0.0172,\n",
      "        -0.0338,  0.0101,  0.0002, -0.0014, -0.0280,  0.0115,  0.0237, -0.0202,\n",
      "        -0.0197,  0.0016,  0.0285, -0.0100, -0.0252,  0.0166, -0.0026,  0.0219,\n",
      "        -0.0257, -0.0307,  0.0342,  0.0321,  0.0306, -0.0112, -0.0102, -0.0183,\n",
      "        -0.0088, -0.0322,  0.0121,  0.0078,  0.0011,  0.0281,  0.0172, -0.0124,\n",
      "         0.0080, -0.0259, -0.0216,  0.0236, -0.0061,  0.0152,  0.0257,  0.0233,\n",
      "        -0.0134,  0.0185,  0.0297, -0.0322,  0.0109,  0.0115, -0.0148,  0.0273,\n",
      "        -0.0097, -0.0163, -0.0025, -0.0180, -0.0058,  0.0277, -0.0156,  0.0013,\n",
      "         0.0016,  0.0322, -0.0070, -0.0189, -0.0071,  0.0247,  0.0100,  0.0315,\n",
      "         0.0236,  0.0131,  0.0132,  0.0331, -0.0254,  0.0127,  0.0293, -0.0226,\n",
      "        -0.0144,  0.0067,  0.0084,  0.0172, -0.0002,  0.0204, -0.0039,  0.0249,\n",
      "         0.0086, -0.0309, -0.0280, -0.0082, -0.0083, -0.0352, -0.0153,  0.0258,\n",
      "        -0.0045, -0.0301,  0.0195,  0.0126, -0.0309,  0.0213,  0.0221, -0.0135,\n",
      "        -0.0308,  0.0241, -0.0140,  0.0160, -0.0201,  0.0143,  0.0147,  0.0010,\n",
      "        -0.0104, -0.0163,  0.0312, -0.0102, -0.0250,  0.0161, -0.0333,  0.0282,\n",
      "        -0.0160, -0.0153, -0.0335,  0.0307, -0.0291,  0.0059,  0.0070,  0.0309,\n",
      "         0.0243, -0.0231,  0.0221,  0.0200,  0.0181,  0.0032,  0.0310,  0.0238,\n",
      "         0.0249,  0.0187, -0.0136, -0.0352,  0.0098,  0.0124, -0.0113,  0.0003,\n",
      "        -0.0309,  0.0044,  0.0228,  0.0319,  0.0281, -0.0348, -0.0258, -0.0183,\n",
      "         0.0183,  0.0008,  0.0139, -0.0327, -0.0323, -0.0096, -0.0322,  0.0003,\n",
      "        -0.0285, -0.0188, -0.0325,  0.0185,  0.0312,  0.0294, -0.0288,  0.0018,\n",
      "         0.0211, -0.0017,  0.0317, -0.0253,  0.0153, -0.0010, -0.0204,  0.0070,\n",
      "         0.0197, -0.0133, -0.0221,  0.0235, -0.0314,  0.0339,  0.0051, -0.0043,\n",
      "        -0.0055,  0.0307,  0.0312,  0.0130,  0.0186, -0.0107, -0.0147, -0.0111,\n",
      "        -0.0142, -0.0029,  0.0219, -0.0142,  0.0171, -0.0096,  0.0208,  0.0269,\n",
      "         0.0137, -0.0338,  0.0272, -0.0085, -0.0310, -0.0047,  0.0088, -0.0223,\n",
      "         0.0114, -0.0328, -0.0038, -0.0187, -0.0123,  0.0332, -0.0147,  0.0113,\n",
      "         0.0200,  0.0261, -0.0021, -0.0354, -0.0226,  0.0229,  0.0335,  0.0338,\n",
      "        -0.0280,  0.0349, -0.0133, -0.0243,  0.0170, -0.0008, -0.0324, -0.0055,\n",
      "        -0.0151, -0.0021, -0.0221,  0.0132,  0.0297,  0.0217, -0.0203,  0.0218,\n",
      "         0.0247,  0.0310,  0.0161,  0.0357, -0.0277,  0.0087,  0.0257,  0.0132,\n",
      "         0.0081, -0.0245, -0.0186,  0.0224], requires_grad=True)), ('weight', Parameter containing:\n",
      "tensor([[ 0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        [-0.0279,  0.0000,  0.0000,  ..., -0.0110,  0.0140, -0.0108],\n",
      "        [-0.0000,  0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "        [-0.0337, -0.0168,  0.0000,  ..., -0.0021,  0.0000,  0.0000],\n",
      "        [-0.0235, -0.0148, -0.0000,  ...,  0.0350, -0.0245, -0.0000]],\n",
      "       requires_grad=True))]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# note how its just 'weight' in the parameters now, not weight_orig\n",
    "prune.remove(module, 'weight')\n",
    "print(list(module.named_parameters()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[('bias_mask', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# no weight_mask anymore \n",
    "print(list(module.named_buffers()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prune Layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "fc1 Linear(in_features=784, out_features=300, bias=True)\n",
      "fc2 Linear(in_features=300, out_features=100, bias=True)\n",
      "fc3 Linear(in_features=100, out_features=10, bias=True)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# look at layers\n",
    "for idx, (name, module) in enumerate(model.named_modules()):\n",
    "    if idx > 0 and idx < 4:\n",
    "        print(name, module)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "for idx, (name, module) in enumerate(model.named_modules()):\n",
    "    if isinstance(module, torch.nn.Linear):\n",
    "        prune.l1_unstructured(module, name='weight', amount=p)\n",
    "        prune.l1_unstructured(module, name='bias', amount=len(module.bias)//2)\n",
    "        \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "dict_keys(['fc1.bias_mask', 'fc1.weight_mask', 'fc2.weight_mask', 'fc2.bias_mask', 'fc3.weight_mask', 'fc3.bias_mask'])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(dict(model.named_buffers()).keys())  # to verify that all masks exist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TODO\n",
    "* Global pruning? \n",
    "* Custom pruning functions? "
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}