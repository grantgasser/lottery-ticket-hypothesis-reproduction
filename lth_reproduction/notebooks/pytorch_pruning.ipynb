{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pruning Demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../src/')\n",
    "\n",
    "from models import LeNetFC \n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LeNetFC().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Inspect a module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight', Parameter containing:\n",
      "tensor([[-0.0060, -0.0218, -0.0119,  ..., -0.0187,  0.0355,  0.0146],\n",
      "        [ 0.0223, -0.0075, -0.0187,  ...,  0.0239,  0.0068,  0.0028],\n",
      "        [-0.0183,  0.0175,  0.0241,  ...,  0.0157,  0.0232,  0.0326],\n",
      "        ...,\n",
      "        [ 0.0110,  0.0016,  0.0083,  ..., -0.0178,  0.0097,  0.0284],\n",
      "        [-0.0129,  0.0260,  0.0183,  ..., -0.0120, -0.0122, -0.0218],\n",
      "        [ 0.0119, -0.0349,  0.0135,  ..., -0.0229,  0.0346,  0.0061]],\n",
      "       requires_grad=True)), ('bias', Parameter containing:\n",
      "tensor([ 0.0231, -0.0195,  0.0143, -0.0247,  0.0069,  0.0042, -0.0328, -0.0053,\n",
      "        -0.0342, -0.0012, -0.0094, -0.0017, -0.0039, -0.0275,  0.0151, -0.0187,\n",
      "        -0.0278,  0.0331,  0.0274,  0.0206, -0.0245,  0.0108,  0.0072, -0.0184,\n",
      "        -0.0230, -0.0148,  0.0305,  0.0239,  0.0032,  0.0075,  0.0340, -0.0310,\n",
      "         0.0081,  0.0151, -0.0034,  0.0098,  0.0079,  0.0126,  0.0023, -0.0291,\n",
      "         0.0154, -0.0120, -0.0121, -0.0089,  0.0281, -0.0163,  0.0135,  0.0300,\n",
      "         0.0181,  0.0158,  0.0140,  0.0206, -0.0189,  0.0099, -0.0235, -0.0305,\n",
      "         0.0293,  0.0342,  0.0357,  0.0195,  0.0295, -0.0278,  0.0254,  0.0221,\n",
      "         0.0008,  0.0105,  0.0349,  0.0135, -0.0243,  0.0130, -0.0126,  0.0348,\n",
      "        -0.0270,  0.0047, -0.0182, -0.0011,  0.0065,  0.0042,  0.0334,  0.0322,\n",
      "         0.0129,  0.0168,  0.0151,  0.0281,  0.0256, -0.0064,  0.0021,  0.0329,\n",
      "        -0.0173, -0.0172,  0.0208,  0.0148,  0.0126, -0.0187, -0.0219, -0.0340,\n",
      "        -0.0278, -0.0040, -0.0130, -0.0036, -0.0352, -0.0221, -0.0182,  0.0061,\n",
      "         0.0017,  0.0245, -0.0028, -0.0219, -0.0233,  0.0339,  0.0313,  0.0187,\n",
      "        -0.0129, -0.0260, -0.0283,  0.0023,  0.0068,  0.0079, -0.0315,  0.0181,\n",
      "         0.0017,  0.0193, -0.0186,  0.0099, -0.0043, -0.0201,  0.0001, -0.0315,\n",
      "        -0.0147, -0.0178, -0.0245,  0.0185, -0.0322,  0.0117,  0.0224,  0.0212,\n",
      "         0.0261, -0.0050, -0.0021,  0.0066,  0.0156, -0.0068, -0.0281, -0.0215,\n",
      "         0.0103, -0.0260, -0.0339,  0.0332,  0.0255, -0.0302,  0.0002,  0.0196,\n",
      "        -0.0089,  0.0347,  0.0132,  0.0195, -0.0263,  0.0339,  0.0265,  0.0122,\n",
      "         0.0027, -0.0136, -0.0007, -0.0330,  0.0353,  0.0161, -0.0051, -0.0239,\n",
      "        -0.0141, -0.0224,  0.0043,  0.0356,  0.0219, -0.0328, -0.0017, -0.0117,\n",
      "        -0.0017, -0.0090, -0.0191,  0.0060, -0.0284, -0.0061, -0.0159,  0.0270,\n",
      "         0.0222,  0.0262,  0.0028, -0.0298, -0.0250, -0.0185,  0.0270, -0.0268,\n",
      "         0.0059,  0.0062, -0.0262,  0.0004, -0.0129, -0.0129,  0.0144, -0.0147,\n",
      "        -0.0154, -0.0144,  0.0178,  0.0184, -0.0283, -0.0198,  0.0137, -0.0176,\n",
      "        -0.0293,  0.0224, -0.0007, -0.0259, -0.0332, -0.0239, -0.0008, -0.0146,\n",
      "        -0.0124, -0.0100, -0.0147, -0.0289,  0.0200, -0.0305, -0.0073,  0.0045,\n",
      "         0.0322,  0.0063,  0.0125, -0.0287, -0.0221,  0.0356,  0.0253, -0.0098,\n",
      "         0.0077,  0.0132,  0.0060, -0.0219, -0.0199, -0.0221,  0.0121, -0.0173,\n",
      "        -0.0220,  0.0288,  0.0002,  0.0152,  0.0234, -0.0253, -0.0025, -0.0276,\n",
      "        -0.0054, -0.0273, -0.0146,  0.0249, -0.0202, -0.0324,  0.0057,  0.0075,\n",
      "         0.0206,  0.0334, -0.0300,  0.0134,  0.0246,  0.0214,  0.0082, -0.0044,\n",
      "        -0.0183,  0.0256, -0.0126,  0.0089, -0.0315, -0.0305, -0.0002, -0.0341,\n",
      "         0.0232,  0.0248, -0.0182, -0.0031, -0.0066, -0.0183, -0.0182,  0.0168,\n",
      "        -0.0310, -0.0076, -0.0015, -0.0213,  0.0122,  0.0057, -0.0046, -0.0241,\n",
      "         0.0279,  0.0293, -0.0261, -0.0079,  0.0344,  0.0041,  0.0007,  0.0284,\n",
      "         0.0180,  0.0011,  0.0328,  0.0019], requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "module = model.fc1\n",
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=300, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# prune the weights (not biases here)\n",
    "p = 0.3\n",
    "pruned_tensor = prune.random_unstructured(module, name='weight', amount=p)\n",
    "print(pruned_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bias', Parameter containing:\n",
      "tensor([ 0.0231, -0.0195,  0.0143, -0.0247,  0.0069,  0.0042, -0.0328, -0.0053,\n",
      "        -0.0342, -0.0012, -0.0094, -0.0017, -0.0039, -0.0275,  0.0151, -0.0187,\n",
      "        -0.0278,  0.0331,  0.0274,  0.0206, -0.0245,  0.0108,  0.0072, -0.0184,\n",
      "        -0.0230, -0.0148,  0.0305,  0.0239,  0.0032,  0.0075,  0.0340, -0.0310,\n",
      "         0.0081,  0.0151, -0.0034,  0.0098,  0.0079,  0.0126,  0.0023, -0.0291,\n",
      "         0.0154, -0.0120, -0.0121, -0.0089,  0.0281, -0.0163,  0.0135,  0.0300,\n",
      "         0.0181,  0.0158,  0.0140,  0.0206, -0.0189,  0.0099, -0.0235, -0.0305,\n",
      "         0.0293,  0.0342,  0.0357,  0.0195,  0.0295, -0.0278,  0.0254,  0.0221,\n",
      "         0.0008,  0.0105,  0.0349,  0.0135, -0.0243,  0.0130, -0.0126,  0.0348,\n",
      "        -0.0270,  0.0047, -0.0182, -0.0011,  0.0065,  0.0042,  0.0334,  0.0322,\n",
      "         0.0129,  0.0168,  0.0151,  0.0281,  0.0256, -0.0064,  0.0021,  0.0329,\n",
      "        -0.0173, -0.0172,  0.0208,  0.0148,  0.0126, -0.0187, -0.0219, -0.0340,\n",
      "        -0.0278, -0.0040, -0.0130, -0.0036, -0.0352, -0.0221, -0.0182,  0.0061,\n",
      "         0.0017,  0.0245, -0.0028, -0.0219, -0.0233,  0.0339,  0.0313,  0.0187,\n",
      "        -0.0129, -0.0260, -0.0283,  0.0023,  0.0068,  0.0079, -0.0315,  0.0181,\n",
      "         0.0017,  0.0193, -0.0186,  0.0099, -0.0043, -0.0201,  0.0001, -0.0315,\n",
      "        -0.0147, -0.0178, -0.0245,  0.0185, -0.0322,  0.0117,  0.0224,  0.0212,\n",
      "         0.0261, -0.0050, -0.0021,  0.0066,  0.0156, -0.0068, -0.0281, -0.0215,\n",
      "         0.0103, -0.0260, -0.0339,  0.0332,  0.0255, -0.0302,  0.0002,  0.0196,\n",
      "        -0.0089,  0.0347,  0.0132,  0.0195, -0.0263,  0.0339,  0.0265,  0.0122,\n",
      "         0.0027, -0.0136, -0.0007, -0.0330,  0.0353,  0.0161, -0.0051, -0.0239,\n",
      "        -0.0141, -0.0224,  0.0043,  0.0356,  0.0219, -0.0328, -0.0017, -0.0117,\n",
      "        -0.0017, -0.0090, -0.0191,  0.0060, -0.0284, -0.0061, -0.0159,  0.0270,\n",
      "         0.0222,  0.0262,  0.0028, -0.0298, -0.0250, -0.0185,  0.0270, -0.0268,\n",
      "         0.0059,  0.0062, -0.0262,  0.0004, -0.0129, -0.0129,  0.0144, -0.0147,\n",
      "        -0.0154, -0.0144,  0.0178,  0.0184, -0.0283, -0.0198,  0.0137, -0.0176,\n",
      "        -0.0293,  0.0224, -0.0007, -0.0259, -0.0332, -0.0239, -0.0008, -0.0146,\n",
      "        -0.0124, -0.0100, -0.0147, -0.0289,  0.0200, -0.0305, -0.0073,  0.0045,\n",
      "         0.0322,  0.0063,  0.0125, -0.0287, -0.0221,  0.0356,  0.0253, -0.0098,\n",
      "         0.0077,  0.0132,  0.0060, -0.0219, -0.0199, -0.0221,  0.0121, -0.0173,\n",
      "        -0.0220,  0.0288,  0.0002,  0.0152,  0.0234, -0.0253, -0.0025, -0.0276,\n",
      "        -0.0054, -0.0273, -0.0146,  0.0249, -0.0202, -0.0324,  0.0057,  0.0075,\n",
      "         0.0206,  0.0334, -0.0300,  0.0134,  0.0246,  0.0214,  0.0082, -0.0044,\n",
      "        -0.0183,  0.0256, -0.0126,  0.0089, -0.0315, -0.0305, -0.0002, -0.0341,\n",
      "         0.0232,  0.0248, -0.0182, -0.0031, -0.0066, -0.0183, -0.0182,  0.0168,\n",
      "        -0.0310, -0.0076, -0.0015, -0.0213,  0.0122,  0.0057, -0.0046, -0.0241,\n",
      "         0.0279,  0.0293, -0.0261, -0.0079,  0.0344,  0.0041,  0.0007,  0.0284,\n",
      "         0.0180,  0.0011,  0.0328,  0.0019], requires_grad=True)), ('weight_orig', Parameter containing:\n",
      "tensor([[-0.0060, -0.0218, -0.0119,  ..., -0.0187,  0.0355,  0.0146],\n",
      "        [ 0.0223, -0.0075, -0.0187,  ...,  0.0239,  0.0068,  0.0028],\n",
      "        [-0.0183,  0.0175,  0.0241,  ...,  0.0157,  0.0232,  0.0326],\n",
      "        ...,\n",
      "        [ 0.0110,  0.0016,  0.0083,  ..., -0.0178,  0.0097,  0.0284],\n",
      "        [-0.0129,  0.0260,  0.0183,  ..., -0.0120, -0.0122, -0.0218],\n",
      "        [ 0.0119, -0.0349,  0.0135,  ..., -0.0229,  0.0346,  0.0061]],\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "# notice 'weight_orig' is stored, 'weight' now contains pruned params\n",
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 0.,  ..., 0., 1., 1.],\n",
      "        [1., 1., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# see mask\n",
    "print(module.weight_mask[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0000, -0.0218, -0.0000,  ..., -0.0000,  0.0355,  0.0146],\n",
      "        [ 0.0223, -0.0075, -0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "# see new pruned params (compare to weight_orig printed above, see how mask is applied?)\n",
    "print(module.weight[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# remove 3 smallest bias params according to L1 norm\n",
    "#prune.l1_unstructured(module, name=\"bias\", amount=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# note bias_orig\n",
    "#print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Iterative Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2940.2097, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total magnitude of weights\n",
    "torch.sum(abs(module.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=300, bias=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.ln_structured(module, name='weight', amount=.5, n=2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1510.6038, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can see half the weights are now zeroed out (pruned/remove)\n",
    "torch.sum(abs(module.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.nn.utils.prune.RandomUnstructured object at 0x7fe910115a50>\n",
      "<torch.nn.utils.prune.LnStructured object at 0x7fe8f02c2990>\n"
     ]
    }
   ],
   "source": [
    "# history of pruning applied to weight param\n",
    "for hook in module._forward_pre_hooks.values():\n",
    "    if hook._tensor_name == 'weight':\n",
    "        break\n",
    "\n",
    "for h in hook:\n",
    "    print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['fc1.bias', 'fc1.weight_orig', 'fc1.weight_mask', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n"
     ]
    }
   ],
   "source": [
    "# serialized and retrievable \n",
    "print(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Make Pruning Permanent\n",
    "Remove pruning re-parametrization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bias', Parameter containing:\n",
      "tensor([-2.6465e-03,  2.5319e-02,  1.3529e-02, -1.3225e-02, -3.9753e-05,\n",
      "         5.4984e-03, -3.2310e-02, -9.5201e-03,  1.2895e-02,  1.1898e-02,\n",
      "         2.1479e-02,  1.6147e-03,  2.4142e-02,  1.6380e-02, -1.8390e-02,\n",
      "         1.9494e-02,  4.0276e-03, -2.1081e-02, -9.9492e-03, -2.3118e-02,\n",
      "         2.6920e-02,  1.7556e-02, -2.7953e-02, -6.7913e-03, -5.4557e-03,\n",
      "        -3.0452e-02, -2.0725e-03, -3.1632e-02, -8.0891e-03, -1.9213e-02,\n",
      "         4.3721e-03, -3.5544e-02,  8.8698e-03,  4.7285e-03, -2.8924e-02,\n",
      "         1.2181e-02, -1.5976e-02,  1.2288e-02, -1.2595e-02, -1.5588e-02,\n",
      "         2.6274e-02, -1.6819e-02, -2.7067e-03, -9.3004e-03, -3.4223e-02,\n",
      "         2.3675e-02, -3.5529e-03,  2.3711e-02,  3.0173e-02,  1.7235e-02,\n",
      "        -5.9229e-03,  9.7212e-03,  3.5452e-02, -3.1832e-02,  3.5085e-02,\n",
      "         8.7124e-04, -1.8860e-02,  1.2506e-02, -8.5054e-03,  1.7609e-02,\n",
      "        -1.2864e-02, -5.9707e-03, -1.6760e-02,  7.2212e-03,  2.5267e-02,\n",
      "         1.0027e-02,  2.8323e-03,  2.3377e-02,  1.8054e-02, -7.0983e-03,\n",
      "         1.1490e-02, -2.8459e-02,  1.7093e-02, -2.8960e-02,  6.4376e-03,\n",
      "        -1.8674e-02,  3.4218e-02,  3.4072e-02, -6.8229e-04, -1.0884e-02,\n",
      "         3.4846e-02, -3.2844e-02, -6.0919e-03, -2.7591e-02,  5.5009e-03,\n",
      "         1.3762e-02, -2.8521e-02,  3.3459e-02,  3.0648e-02,  5.8399e-03,\n",
      "         1.9712e-02, -6.2234e-03,  4.7661e-03, -1.8001e-02,  2.7406e-02,\n",
      "         1.1250e-02, -2.1053e-02, -2.2682e-02,  7.7320e-03, -1.6753e-03,\n",
      "        -1.4913e-02, -2.2449e-02,  1.5430e-03, -1.1992e-02, -2.7199e-02,\n",
      "         2.6116e-02,  3.2521e-02, -1.9480e-02,  2.1415e-02, -2.1564e-02,\n",
      "        -3.3082e-02, -2.9417e-02, -1.2581e-02,  7.2655e-03,  3.5680e-03,\n",
      "        -2.6625e-02,  3.5112e-02,  3.1009e-02,  1.0490e-03, -2.7587e-02,\n",
      "        -4.9867e-03,  3.4033e-02,  2.2251e-02,  7.0562e-03, -3.1254e-02,\n",
      "        -5.8236e-03,  2.1225e-02,  1.7638e-02, -2.2289e-03,  3.3435e-02,\n",
      "        -5.9491e-03,  4.7125e-03, -9.4173e-03,  1.8065e-02,  2.3266e-02,\n",
      "        -5.8001e-03,  2.2095e-02,  4.3716e-03, -2.4129e-02, -4.5184e-03,\n",
      "         7.6116e-03, -3.3707e-02,  3.3875e-02,  1.4756e-02,  7.8656e-03,\n",
      "        -7.6428e-03,  1.0814e-02,  3.2460e-02,  2.9950e-02,  1.4741e-02,\n",
      "         2.5456e-02, -7.0885e-04,  1.2445e-02,  5.9134e-03, -4.7844e-03,\n",
      "        -2.3071e-02,  2.6944e-02,  1.4302e-02,  2.8097e-02, -2.1392e-02,\n",
      "        -3.3994e-02, -1.2603e-02, -2.2816e-02,  9.5853e-03,  2.0401e-02,\n",
      "         6.3709e-03,  1.6979e-02, -1.3431e-02,  1.9678e-02,  3.2228e-02,\n",
      "         9.9669e-04,  4.2740e-03, -2.7182e-02, -2.0749e-03, -2.1800e-02,\n",
      "         2.7067e-02,  1.8144e-02, -3.1438e-02,  1.2059e-02,  1.2449e-02,\n",
      "         3.2761e-02,  1.3880e-02, -1.8371e-02,  2.0782e-02, -8.9971e-03,\n",
      "         2.3708e-02, -2.4577e-02, -7.8929e-03,  2.2392e-02,  2.2810e-02,\n",
      "        -1.7848e-02,  9.0273e-03, -1.7491e-03,  2.8525e-02, -4.3801e-03,\n",
      "        -1.6771e-02,  2.9895e-02,  7.1457e-03,  1.1379e-02, -2.9013e-02,\n",
      "         3.0535e-02,  6.3124e-03,  1.3588e-02, -5.2786e-03, -1.1574e-02,\n",
      "        -1.3081e-02,  2.0058e-02, -3.0584e-02, -2.3997e-03,  1.5712e-02,\n",
      "        -3.1598e-03,  2.3372e-02,  2.3028e-02,  1.8010e-03,  1.6956e-02,\n",
      "        -1.3763e-02, -2.0282e-02,  1.7410e-02, -1.0434e-02,  2.6184e-02,\n",
      "         7.0659e-03,  3.1290e-02, -1.4621e-02, -1.5346e-02, -8.5600e-03,\n",
      "        -3.3311e-02, -1.1355e-02, -2.1650e-02,  6.5561e-03, -4.8374e-03,\n",
      "        -8.7759e-03,  1.0335e-02, -2.3296e-02,  2.9928e-02,  2.5985e-02,\n",
      "         2.6286e-02,  6.0880e-04,  3.4076e-02,  8.8225e-03,  9.1373e-03,\n",
      "         1.6315e-03, -2.8574e-02, -3.4206e-02, -3.1771e-02,  1.4522e-02,\n",
      "         1.4007e-02,  9.2533e-03, -2.1566e-02,  3.4387e-03,  1.5036e-02,\n",
      "         1.6536e-02, -1.5269e-02, -1.9709e-02,  3.0793e-03, -3.5710e-02,\n",
      "         3.0793e-02, -2.9269e-02,  1.4128e-02, -3.3814e-02, -2.2343e-02,\n",
      "        -3.3296e-02, -2.5135e-02, -3.0441e-02, -2.6001e-02,  1.2600e-02,\n",
      "        -3.2931e-02, -1.2499e-02,  6.8743e-03, -2.3372e-03, -2.8753e-03,\n",
      "        -1.6034e-02,  1.4168e-02, -1.1417e-03, -3.3750e-02,  1.8565e-02,\n",
      "         3.1061e-02,  2.6662e-02, -1.2161e-02,  1.4468e-02, -6.6780e-03,\n",
      "        -2.3415e-02,  1.0833e-02,  2.6462e-02,  2.0180e-02, -2.0215e-02,\n",
      "        -1.6479e-02,  9.8036e-03, -2.3416e-02,  6.8564e-03, -2.4166e-02,\n",
      "         2.9136e-02,  5.6065e-04, -1.1916e-02, -2.5063e-02,  3.0378e-02,\n",
      "        -4.4897e-03, -3.4430e-02, -3.3301e-02,  1.1108e-02,  6.8008e-03],\n",
      "       requires_grad=True)), ('weight_orig', Parameter containing:\n",
      "tensor([[ 0.0070,  0.0059, -0.0071,  ...,  0.0253,  0.0231, -0.0355],\n",
      "        [ 0.0097, -0.0302, -0.0115,  ...,  0.0227, -0.0311,  0.0041],\n",
      "        [-0.0179, -0.0330, -0.0082,  ...,  0.0196, -0.0244, -0.0328],\n",
      "        ...,\n",
      "        [-0.0266,  0.0056, -0.0123,  ..., -0.0108,  0.0345,  0.0280],\n",
      "        [-0.0310,  0.0209,  0.0182,  ...,  0.0353, -0.0021, -0.0317],\n",
      "        [-0.0007,  0.0263,  0.0182,  ...,  0.0351,  0.0273,  0.0134]],\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "# Before: with weight_orig in the named_paramaters\n",
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_mask', tensor([[0., 1., 0.,  ..., 1., 0., 1.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 1.],\n",
      "        [1., 0., 1.,  ..., 1., 1., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]))]\n"
     ]
    }
   ],
   "source": [
    "# Before: \n",
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0059, -0.0000,  ...,  0.0253,  0.0000, -0.0355],\n",
      "        [ 0.0097, -0.0302, -0.0115,  ...,  0.0000, -0.0000,  0.0041],\n",
      "        [-0.0179, -0.0000, -0.0082,  ...,  0.0196, -0.0244, -0.0000],\n",
      "        ...,\n",
      "        [-0.0266,  0.0056, -0.0123,  ..., -0.0000,  0.0345,  0.0000],\n",
      "        [-0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "        [-0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Before\n",
    "print(module.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bias', Parameter containing:\n",
      "tensor([-2.6465e-03,  2.5319e-02,  1.3529e-02, -1.3225e-02, -3.9753e-05,\n",
      "         5.4984e-03, -3.2310e-02, -9.5201e-03,  1.2895e-02,  1.1898e-02,\n",
      "         2.1479e-02,  1.6147e-03,  2.4142e-02,  1.6380e-02, -1.8390e-02,\n",
      "         1.9494e-02,  4.0276e-03, -2.1081e-02, -9.9492e-03, -2.3118e-02,\n",
      "         2.6920e-02,  1.7556e-02, -2.7953e-02, -6.7913e-03, -5.4557e-03,\n",
      "        -3.0452e-02, -2.0725e-03, -3.1632e-02, -8.0891e-03, -1.9213e-02,\n",
      "         4.3721e-03, -3.5544e-02,  8.8698e-03,  4.7285e-03, -2.8924e-02,\n",
      "         1.2181e-02, -1.5976e-02,  1.2288e-02, -1.2595e-02, -1.5588e-02,\n",
      "         2.6274e-02, -1.6819e-02, -2.7067e-03, -9.3004e-03, -3.4223e-02,\n",
      "         2.3675e-02, -3.5529e-03,  2.3711e-02,  3.0173e-02,  1.7235e-02,\n",
      "        -5.9229e-03,  9.7212e-03,  3.5452e-02, -3.1832e-02,  3.5085e-02,\n",
      "         8.7124e-04, -1.8860e-02,  1.2506e-02, -8.5054e-03,  1.7609e-02,\n",
      "        -1.2864e-02, -5.9707e-03, -1.6760e-02,  7.2212e-03,  2.5267e-02,\n",
      "         1.0027e-02,  2.8323e-03,  2.3377e-02,  1.8054e-02, -7.0983e-03,\n",
      "         1.1490e-02, -2.8459e-02,  1.7093e-02, -2.8960e-02,  6.4376e-03,\n",
      "        -1.8674e-02,  3.4218e-02,  3.4072e-02, -6.8229e-04, -1.0884e-02,\n",
      "         3.4846e-02, -3.2844e-02, -6.0919e-03, -2.7591e-02,  5.5009e-03,\n",
      "         1.3762e-02, -2.8521e-02,  3.3459e-02,  3.0648e-02,  5.8399e-03,\n",
      "         1.9712e-02, -6.2234e-03,  4.7661e-03, -1.8001e-02,  2.7406e-02,\n",
      "         1.1250e-02, -2.1053e-02, -2.2682e-02,  7.7320e-03, -1.6753e-03,\n",
      "        -1.4913e-02, -2.2449e-02,  1.5430e-03, -1.1992e-02, -2.7199e-02,\n",
      "         2.6116e-02,  3.2521e-02, -1.9480e-02,  2.1415e-02, -2.1564e-02,\n",
      "        -3.3082e-02, -2.9417e-02, -1.2581e-02,  7.2655e-03,  3.5680e-03,\n",
      "        -2.6625e-02,  3.5112e-02,  3.1009e-02,  1.0490e-03, -2.7587e-02,\n",
      "        -4.9867e-03,  3.4033e-02,  2.2251e-02,  7.0562e-03, -3.1254e-02,\n",
      "        -5.8236e-03,  2.1225e-02,  1.7638e-02, -2.2289e-03,  3.3435e-02,\n",
      "        -5.9491e-03,  4.7125e-03, -9.4173e-03,  1.8065e-02,  2.3266e-02,\n",
      "        -5.8001e-03,  2.2095e-02,  4.3716e-03, -2.4129e-02, -4.5184e-03,\n",
      "         7.6116e-03, -3.3707e-02,  3.3875e-02,  1.4756e-02,  7.8656e-03,\n",
      "        -7.6428e-03,  1.0814e-02,  3.2460e-02,  2.9950e-02,  1.4741e-02,\n",
      "         2.5456e-02, -7.0885e-04,  1.2445e-02,  5.9134e-03, -4.7844e-03,\n",
      "        -2.3071e-02,  2.6944e-02,  1.4302e-02,  2.8097e-02, -2.1392e-02,\n",
      "        -3.3994e-02, -1.2603e-02, -2.2816e-02,  9.5853e-03,  2.0401e-02,\n",
      "         6.3709e-03,  1.6979e-02, -1.3431e-02,  1.9678e-02,  3.2228e-02,\n",
      "         9.9669e-04,  4.2740e-03, -2.7182e-02, -2.0749e-03, -2.1800e-02,\n",
      "         2.7067e-02,  1.8144e-02, -3.1438e-02,  1.2059e-02,  1.2449e-02,\n",
      "         3.2761e-02,  1.3880e-02, -1.8371e-02,  2.0782e-02, -8.9971e-03,\n",
      "         2.3708e-02, -2.4577e-02, -7.8929e-03,  2.2392e-02,  2.2810e-02,\n",
      "        -1.7848e-02,  9.0273e-03, -1.7491e-03,  2.8525e-02, -4.3801e-03,\n",
      "        -1.6771e-02,  2.9895e-02,  7.1457e-03,  1.1379e-02, -2.9013e-02,\n",
      "         3.0535e-02,  6.3124e-03,  1.3588e-02, -5.2786e-03, -1.1574e-02,\n",
      "        -1.3081e-02,  2.0058e-02, -3.0584e-02, -2.3997e-03,  1.5712e-02,\n",
      "        -3.1598e-03,  2.3372e-02,  2.3028e-02,  1.8010e-03,  1.6956e-02,\n",
      "        -1.3763e-02, -2.0282e-02,  1.7410e-02, -1.0434e-02,  2.6184e-02,\n",
      "         7.0659e-03,  3.1290e-02, -1.4621e-02, -1.5346e-02, -8.5600e-03,\n",
      "        -3.3311e-02, -1.1355e-02, -2.1650e-02,  6.5561e-03, -4.8374e-03,\n",
      "        -8.7759e-03,  1.0335e-02, -2.3296e-02,  2.9928e-02,  2.5985e-02,\n",
      "         2.6286e-02,  6.0880e-04,  3.4076e-02,  8.8225e-03,  9.1373e-03,\n",
      "         1.6315e-03, -2.8574e-02, -3.4206e-02, -3.1771e-02,  1.4522e-02,\n",
      "         1.4007e-02,  9.2533e-03, -2.1566e-02,  3.4387e-03,  1.5036e-02,\n",
      "         1.6536e-02, -1.5269e-02, -1.9709e-02,  3.0793e-03, -3.5710e-02,\n",
      "         3.0793e-02, -2.9269e-02,  1.4128e-02, -3.3814e-02, -2.2343e-02,\n",
      "        -3.3296e-02, -2.5135e-02, -3.0441e-02, -2.6001e-02,  1.2600e-02,\n",
      "        -3.2931e-02, -1.2499e-02,  6.8743e-03, -2.3372e-03, -2.8753e-03,\n",
      "        -1.6034e-02,  1.4168e-02, -1.1417e-03, -3.3750e-02,  1.8565e-02,\n",
      "         3.1061e-02,  2.6662e-02, -1.2161e-02,  1.4468e-02, -6.6780e-03,\n",
      "        -2.3415e-02,  1.0833e-02,  2.6462e-02,  2.0180e-02, -2.0215e-02,\n",
      "        -1.6479e-02,  9.8036e-03, -2.3416e-02,  6.8564e-03, -2.4166e-02,\n",
      "         2.9136e-02,  5.6065e-04, -1.1916e-02, -2.5063e-02,  3.0378e-02,\n",
      "        -4.4897e-03, -3.4430e-02, -3.3301e-02,  1.1108e-02,  6.8008e-03],\n",
      "       requires_grad=True)), ('weight', Parameter containing:\n",
      "tensor([[ 0.0000,  0.0059, -0.0000,  ...,  0.0253,  0.0000, -0.0355],\n",
      "        [ 0.0097, -0.0302, -0.0115,  ...,  0.0000, -0.0000,  0.0041],\n",
      "        [-0.0179, -0.0000, -0.0082,  ...,  0.0196, -0.0244, -0.0000],\n",
      "        ...,\n",
      "        [-0.0266,  0.0056, -0.0123,  ..., -0.0000,  0.0345,  0.0000],\n",
      "        [-0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "        [-0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "# note how its just 'weight' in the parameters now, not weight_orig\n",
    "prune.remove(module, 'weight')\n",
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# no weight_mask anymore \n",
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prune Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1 Linear(in_features=784, out_features=300, bias=True)\n",
      "fc2 Linear(in_features=300, out_features=100, bias=True)\n",
      "fc3 Linear(in_features=100, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# look at layers\n",
    "for idx, (name, module) in enumerate(model.named_modules()):\n",
    "    if idx > 0 and idx < 4:\n",
    "        print(name, module)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for idx, (name, module) in enumerate(model.named_modules()):\n",
    "    if isinstance(module, torch.nn.Linear):\n",
    "        prune.l1_unstructured(module, name='weight', amount=p)\n",
    "        prune.l1_unstructured(module, name='bias', amount=len(module.bias)//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['fc1.weight_mask', 'fc1.bias_mask', 'fc2.weight_mask', 'fc2.bias_mask', 'fc3.weight_mask', 'fc3.bias_mask'])\n"
     ]
    }
   ],
   "source": [
    "print(dict(model.named_buffers()).keys())  # to verify that all masks exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning Container for Iterative Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load FC2 layer module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=300, out_features=100, bias=True)\n"
     ]
    }
   ],
   "source": [
    "fc2_module = model.fc2\n",
    "print(fc2_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0571, -0.0313,  0.0509,  ..., -0.0313, -0.0230, -0.0480],\n",
       "          [-0.0507,  0.0363,  0.0012,  ..., -0.0116, -0.0488,  0.0446],\n",
       "          [ 0.0556,  0.0529, -0.0282,  ...,  0.0096, -0.0392,  0.0090],\n",
       "          ...,\n",
       "          [ 0.0095, -0.0503,  0.0200,  ..., -0.0385, -0.0335, -0.0384],\n",
       "          [-0.0177, -0.0288, -0.0486,  ...,  0.0447, -0.0326, -0.0449],\n",
       "          [ 0.0238, -0.0117,  0.0345,  ..., -0.0086, -0.0463,  0.0420]],\n",
       "         requires_grad=True)),\n",
       " ('bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0165, -0.0475,  0.0276,  0.0074,  0.0144, -0.0508,  0.0158, -0.0143,\n",
       "           0.0308, -0.0459, -0.0136, -0.0099, -0.0464, -0.0151,  0.0182, -0.0118,\n",
       "           0.0114, -0.0267, -0.0393, -0.0225,  0.0266, -0.0448,  0.0501,  0.0438,\n",
       "           0.0325, -0.0140,  0.0118,  0.0167, -0.0183, -0.0093,  0.0045, -0.0577,\n",
       "           0.0123,  0.0384, -0.0037,  0.0513,  0.0098, -0.0497,  0.0486,  0.0246,\n",
       "           0.0140, -0.0477, -0.0268, -0.0076, -0.0155, -0.0374,  0.0231,  0.0372,\n",
       "          -0.0025,  0.0414,  0.0163,  0.0543,  0.0188,  0.0540,  0.0557, -0.0388,\n",
       "          -0.0089,  0.0378,  0.0262,  0.0457,  0.0396,  0.0044, -0.0520,  0.0098,\n",
       "           0.0133, -0.0374, -0.0359, -0.0026, -0.0449,  0.0391, -0.0342,  0.0143,\n",
       "           0.0031,  0.0542,  0.0185, -0.0498,  0.0264,  0.0254, -0.0041,  0.0414,\n",
       "           0.0310,  0.0224,  0.0452, -0.0045,  0.0172, -0.0448, -0.0475,  0.0338,\n",
       "           0.0434,  0.0115,  0.0103, -0.0211,  0.0127,  0.0208,  0.0524,  0.0321,\n",
       "          -0.0524, -0.0481,  0.0161, -0.0395], requires_grad=True))]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fc2_module.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=300, out_features=100, bias=True)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.l1_unstructured(fc2_module, name='weight', amount=.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0571, -0.0000,  0.0509,  ..., -0.0000, -0.0000, -0.0480],\n",
      "        [-0.0507,  0.0363,  0.0000,  ..., -0.0000, -0.0488,  0.0446],\n",
      "        [ 0.0556,  0.0529, -0.0000,  ...,  0.0000, -0.0392,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000, -0.0503,  0.0000,  ..., -0.0385, -0.0000, -0.0384],\n",
      "        [-0.0000, -0.0000, -0.0486,  ...,  0.0447, -0.0000, -0.0449],\n",
      "        [ 0.0000, -0.0000,  0.0345,  ..., -0.0000, -0.0463,  0.0420]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[1., 0., 1.,  ..., 0., 0., 1.],\n",
      "        [1., 1., 0.,  ..., 0., 1., 1.],\n",
      "        [1., 1., 0.,  ..., 0., 1., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.,  ..., 1., 0., 1.],\n",
      "        [0., 0., 1.,  ..., 1., 0., 1.],\n",
      "        [0., 0., 1.,  ..., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# named_parameters has weight_orig now\n",
    "print(fc2_module.weight)\n",
    "print(fc2_module.weight_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(863.4540, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# value of all original weights (weight_orig)\n",
    "torch.sum(torch.abs(list(fc2_module.named_parameters())[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(552.8780, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# roughly 60%\n",
    "torch.sum(abs(fc2_module.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=300, out_features=100, bias=True)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make first prune permanent\n",
    "prune.remove(fc2_module, 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(552.8780, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be 60% now or roughly 552\n",
    "torch.sum(torch.abs(list(fc2_module.named_parameters())[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=300, out_features=100, bias=True)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next pruning iteration \n",
    "prune.l1_unstructured(fc2_module, name='weight', amount=.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0165, -0.0475,  0.0276,  0.0074,  0.0144, -0.0508,  0.0158, -0.0143,\n",
       "           0.0308, -0.0459, -0.0136, -0.0099, -0.0464, -0.0151,  0.0182, -0.0118,\n",
       "           0.0114, -0.0267, -0.0393, -0.0225,  0.0266, -0.0448,  0.0501,  0.0438,\n",
       "           0.0325, -0.0140,  0.0118,  0.0167, -0.0183, -0.0093,  0.0045, -0.0577,\n",
       "           0.0123,  0.0384, -0.0037,  0.0513,  0.0098, -0.0497,  0.0486,  0.0246,\n",
       "           0.0140, -0.0477, -0.0268, -0.0076, -0.0155, -0.0374,  0.0231,  0.0372,\n",
       "          -0.0025,  0.0414,  0.0163,  0.0543,  0.0188,  0.0540,  0.0557, -0.0388,\n",
       "          -0.0089,  0.0378,  0.0262,  0.0457,  0.0396,  0.0044, -0.0520,  0.0098,\n",
       "           0.0133, -0.0374, -0.0359, -0.0026, -0.0449,  0.0391, -0.0342,  0.0143,\n",
       "           0.0031,  0.0542,  0.0185, -0.0498,  0.0264,  0.0254, -0.0041,  0.0414,\n",
       "           0.0310,  0.0224,  0.0452, -0.0045,  0.0172, -0.0448, -0.0475,  0.0338,\n",
       "           0.0434,  0.0115,  0.0103, -0.0211,  0.0127,  0.0208,  0.0524,  0.0321,\n",
       "          -0.0524, -0.0481,  0.0161, -0.0395], requires_grad=True)),\n",
       " ('weight_orig',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0571, -0.0000,  0.0509,  ..., -0.0000, -0.0000, -0.0480],\n",
       "          [-0.0507,  0.0363,  0.0000,  ..., -0.0000, -0.0488,  0.0446],\n",
       "          [ 0.0556,  0.0529, -0.0000,  ...,  0.0000, -0.0392,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000, -0.0503,  0.0000,  ..., -0.0385, -0.0000, -0.0384],\n",
       "          [-0.0000, -0.0000, -0.0486,  ...,  0.0447, -0.0000, -0.0449],\n",
       "          [ 0.0000, -0.0000,  0.0345,  ..., -0.0000, -0.0463,  0.0420]],\n",
       "         requires_grad=True))]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now weight_orig is not the weights before pruning, but the weight before this specific pruning step\n",
    "list(fc2_module.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(552.8780, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.abs(list(fc2_module.named_parameters())[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(552.8780, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be roughly 40% of 552, but its still 552! -- HERES THE PROBLEM \n",
    "torch.sum(abs(fc2_module.weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to \"remove\" after both pruning steps have been applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload FC model since fc2 module has been changed \n",
    "model = LeNetFC().to(device)\n",
    "fc2_module = model.fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0545, -0.0436,  0.0258,  ...,  0.0039, -0.0443, -0.0524],\n",
       "          [-0.0548,  0.0324,  0.0165,  ...,  0.0058, -0.0258, -0.0042],\n",
       "          [-0.0028,  0.0349,  0.0082,  ...,  0.0084,  0.0015, -0.0075],\n",
       "          ...,\n",
       "          [ 0.0412, -0.0450,  0.0222,  ...,  0.0240,  0.0115,  0.0080],\n",
       "          [ 0.0036,  0.0430, -0.0047,  ...,  0.0107, -0.0437,  0.0300],\n",
       "          [-0.0123,  0.0268,  0.0109,  ...,  0.0131, -0.0397,  0.0510]],\n",
       "         requires_grad=True)),\n",
       " ('bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0323, -0.0114,  0.0135,  0.0502,  0.0495, -0.0440,  0.0510, -0.0386,\n",
       "           0.0079,  0.0013, -0.0199, -0.0119, -0.0153, -0.0424, -0.0486,  0.0399,\n",
       "          -0.0167, -0.0399,  0.0238,  0.0025, -0.0201, -0.0229, -0.0247,  0.0334,\n",
       "          -0.0066,  0.0481,  0.0128,  0.0372,  0.0081, -0.0062,  0.0534,  0.0568,\n",
       "          -0.0334, -0.0539, -0.0522,  0.0269, -0.0117, -0.0299,  0.0328, -0.0458,\n",
       "          -0.0125,  0.0021,  0.0016,  0.0434, -0.0479, -0.0075, -0.0533, -0.0094,\n",
       "          -0.0285,  0.0383,  0.0487,  0.0169, -0.0393, -0.0447, -0.0027,  0.0111,\n",
       "           0.0206, -0.0035,  0.0484,  0.0011, -0.0486, -0.0075,  0.0403,  0.0547,\n",
       "          -0.0138, -0.0356,  0.0332, -0.0441, -0.0510,  0.0378, -0.0540, -0.0331,\n",
       "           0.0277, -0.0499,  0.0038,  0.0097, -0.0200, -0.0343,  0.0339, -0.0345,\n",
       "           0.0575,  0.0131, -0.0233,  0.0317, -0.0456,  0.0575,  0.0263, -0.0195,\n",
       "           0.0492, -0.0278, -0.0422,  0.0086, -0.0344,  0.0382, -0.0095, -0.0017,\n",
       "          -0.0375, -0.0055,  0.0169, -0.0464], requires_grad=True))]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fc2_module.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=300, out_features=100, bias=True)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.l1_unstructured(fc2_module, name='weight', amount=.6)\n",
    "prune.l1_unstructured(fc2_module, name='weight', amount=.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.nn.utils.prune.L1Unstructured object at 0x7fe910ba8b90> 0.6\n",
      "<torch.nn.utils.prune.L1Unstructured object at 0x7fe910ba8210> 0.4\n"
     ]
    }
   ],
   "source": [
    "# history of pruning applied to weight param\n",
    "for hook in fc2_module._forward_pre_hooks.values():\n",
    "    if hook._tensor_name == 'weight':\n",
    "        break\n",
    "\n",
    "for h in hook:\n",
    "    print(h, h.amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(867.2637, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.abs(list(fc2_module.named_parameters())[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(365.2234, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BAD: pytorch prunes .4 of original weights! instead it should prune .4 of the .6 remaining weights!\n",
    "torch.sum(abs(fc2_module.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208.07999999999998"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be this much left\n",
    "(.6 * 867)*.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346.8"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but this is how much is left \n",
    ".4*867"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=300, out_features=100, bias=True)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.remove(fc2_module, 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(365.2234, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.abs(list(fc2_module.named_parameters())[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to do on my own because pytorch is stupid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload FC model since fc2 module has been changed \n",
    "model = LeNetFC().to(device)\n",
    "fc2_module = model.fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0474,  0.0063, -0.0233,  ..., -0.0230, -0.0287,  0.0006],\n",
       "          [-0.0418,  0.0276, -0.0396,  ...,  0.0406,  0.0070,  0.0261],\n",
       "          [ 0.0473, -0.0533, -0.0564,  ..., -0.0090, -0.0297, -0.0120],\n",
       "          ...,\n",
       "          [-0.0546,  0.0388,  0.0545,  ..., -0.0157,  0.0194, -0.0388],\n",
       "          [ 0.0576,  0.0390, -0.0176,  ..., -0.0220, -0.0543, -0.0045],\n",
       "          [ 0.0191, -0.0024, -0.0301,  ..., -0.0111,  0.0191, -0.0450]],\n",
       "         requires_grad=True)),\n",
       " ('bias',\n",
       "  Parameter containing:\n",
       "  tensor([-2.9264e-02,  4.1564e-02, -4.4723e-03, -4.1308e-02,  2.0183e-02,\n",
       "          -3.9997e-02,  1.3494e-02,  4.3906e-02,  4.8878e-02,  5.4643e-02,\n",
       "           2.4308e-02, -8.1346e-03, -1.7897e-02,  1.3112e-02,  4.4896e-02,\n",
       "          -1.9509e-02,  4.8706e-02,  5.0557e-03, -4.9757e-02, -1.4422e-02,\n",
       "           7.4990e-03,  3.1629e-02, -5.1888e-02, -5.3309e-02, -3.4581e-02,\n",
       "          -6.1646e-03,  1.6914e-02,  4.8195e-02, -5.8696e-03, -2.8868e-02,\n",
       "           9.8138e-03,  3.4626e-02,  2.9248e-02,  1.5130e-02,  1.7197e-02,\n",
       "          -5.4274e-02,  3.9517e-02, -3.6111e-02,  2.9635e-03, -3.3560e-03,\n",
       "          -4.9516e-02,  5.6809e-03, -4.4518e-02, -2.3458e-02,  3.0740e-02,\n",
       "           3.1340e-03,  1.5138e-02,  5.0428e-02, -4.8060e-02,  3.0191e-02,\n",
       "           6.1835e-03,  4.9909e-02, -5.9455e-03, -3.0492e-02, -3.8854e-02,\n",
       "          -2.9583e-02,  4.9876e-02, -4.7084e-03,  1.1620e-02,  4.2396e-02,\n",
       "           5.0309e-02,  2.1597e-02, -5.2476e-02,  9.6922e-03,  8.3685e-03,\n",
       "           5.1356e-02,  3.6277e-02,  1.2345e-02, -5.1995e-02,  5.5500e-02,\n",
       "           3.8134e-03, -4.0473e-02, -4.3675e-03, -8.9165e-05, -5.7409e-02,\n",
       "          -4.0679e-03, -4.7367e-03,  1.1046e-02,  3.6799e-02, -3.7847e-02,\n",
       "           3.6789e-02,  6.3670e-03,  1.6398e-02,  1.0362e-02,  1.5629e-02,\n",
       "          -3.8861e-02,  1.9776e-02, -5.1655e-02, -1.2318e-02,  2.0268e-02,\n",
       "          -3.2209e-02, -3.5803e-02,  4.8170e-03, -2.7639e-02,  9.9350e-03,\n",
       "           1.0105e-02,  2.4426e-02,  5.2835e-02, -1.8982e-02, -3.9743e-02],\n",
       "         requires_grad=True))]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fc2_module.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(864.4819, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# careful with indexes! need to check if 'weight' or 'weight_orig'\n",
    "torch.sum(torch.abs(list(fc2_module.named_parameters())[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=300, out_features=100, bias=True)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_module = prune.l1_unstructured(fc2_module, name='weight', amount=.6)\n",
    "pruned_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0474,  0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
       "        [-0.0418,  0.0000, -0.0396,  ...,  0.0406,  0.0000,  0.0000],\n",
       "        [ 0.0473, -0.0533, -0.0564,  ..., -0.0000, -0.0000, -0.0000],\n",
       "        ...,\n",
       "        [-0.0546,  0.0388,  0.0545,  ..., -0.0000,  0.0000, -0.0388],\n",
       "        [ 0.0576,  0.0390, -0.0000,  ..., -0.0000, -0.0543, -0.0000],\n",
       "        [ 0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.0000, -0.0450]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_module.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 1.,  ..., 1., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 0., 0., 1.],\n",
       "        [1., 1., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_module.weight_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(864.4819, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.abs(list(fc2_module.named_parameters())[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(554.0620, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.abs(pruned_module.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could be dangerous to change these class variables directly, but there is no function to do so..\n",
    "fc2_module._parameters['weight_orig'] = pruned_module.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0474,  0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
       "        [-0.0418,  0.0000, -0.0396,  ...,  0.0406,  0.0000,  0.0000],\n",
       "        [ 0.0473, -0.0533, -0.0564,  ..., -0.0000, -0.0000, -0.0000],\n",
       "        ...,\n",
       "        [-0.0546,  0.0388,  0.0545,  ..., -0.0000,  0.0000, -0.0388],\n",
       "        [ 0.0576,  0.0390, -0.0000,  ..., -0.0000, -0.0543, -0.0000],\n",
       "        [ 0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.0000, -0.0450]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc2_module._parameters['weight_orig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(554.0620, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ok this is good\n",
    "torch.sum(torch.abs(list(fc2_module.named_parameters())[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=300, out_features=100, bias=True)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_module = prune.l1_unstructured(fc2_module, name='weight', amount=.4)\n",
    "pruned_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0474,  0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
       "        [-0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0473, -0.0533, -0.0564,  ..., -0.0000, -0.0000, -0.0000],\n",
       "        ...,\n",
       "        [-0.0546,  0.0000,  0.0545,  ..., -0.0000,  0.0000, -0.0000],\n",
       "        [ 0.0576,  0.0000, -0.0000,  ..., -0.0000, -0.0543, -0.0000],\n",
       "        [ 0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.0000, -0.0450]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_module.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(365.7526, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.abs(pruned_module.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc2_module._parameters['weight_orig'] = pruned_module.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0474,  0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
       "        [-0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0473, -0.0533, -0.0564,  ..., -0.0000, -0.0000, -0.0000],\n",
       "        ...,\n",
       "        [-0.0546,  0.0000,  0.0545,  ..., -0.0000,  0.0000, -0.0000],\n",
       "        [ 0.0576,  0.0000, -0.0000,  ..., -0.0000, -0.0543, -0.0000],\n",
       "        [ 0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.0000, -0.0450]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc2_module._parameters['weight_orig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(365.7526, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# still doesn't work, just does .4 * 864 \n",
    "torch.sum(torch.abs(list(fc2_module.named_parameters())[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207.475656"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(.6 * 864.4819) * .4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to prune completely without pytorch pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload FC model since fc2 module has been changed \n",
    "model = LeNetFC().to(device)\n",
    "fc2_module = model.fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(860.0298, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.abs(list(fc2_module.named_parameters())[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [1., 1., 0.,  ..., 1., 1., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 1.,  ..., 0., 1., 0.],\n",
       "        [1., 1., 0.,  ..., 0., 1., 0.],\n",
       "        [1., 0., 1.,  ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nparams_toprune = int(round(0.6 * fc2_module.weight.nelement()))\n",
    "topk = torch.topk(torch.abs(fc2_module.weight).view(-1), k=nparams_toprune, largest=False)\n",
    "\n",
    "orig = fc2_module.weight\n",
    "mask = torch.ones_like(orig)\n",
    "mask.view(-1)[topk.indices] = 0\n",
    "\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0572, -0.0097, -0.0082,  ...,  0.0041, -0.0560, -0.0169],\n",
       "        [ 0.0416,  0.0504,  0.0343,  ..., -0.0385, -0.0532, -0.0116],\n",
       "        [ 0.0148, -0.0199, -0.0506,  ..., -0.0227,  0.0029, -0.0556],\n",
       "        ...,\n",
       "        [-0.0180,  0.0263,  0.0502,  ...,  0.0262,  0.0571,  0.0259],\n",
       "        [-0.0543, -0.0424,  0.0031,  ..., -0.0163, -0.0508, -0.0111],\n",
       "        [-0.0448, -0.0203, -0.0421,  ..., -0.0070,  0.0426, -0.0152]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc2_module.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0572, -0.0000, -0.0000,  ...,  0.0000, -0.0560, -0.0000],\n",
       "        [ 0.0416,  0.0504,  0.0000,  ..., -0.0385, -0.0532, -0.0000],\n",
       "        [ 0.0000, -0.0000, -0.0506,  ..., -0.0000,  0.0000, -0.0556],\n",
       "        ...,\n",
       "        [-0.0000,  0.0000,  0.0502,  ...,  0.0000,  0.0571,  0.0000],\n",
       "        [-0.0543, -0.0424,  0.0000,  ..., -0.0000, -0.0508, -0.0000],\n",
       "        [-0.0448, -0.0000, -0.0421,  ..., -0.0000,  0.0426, -0.0000]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_module = mask * fc2_module.weight\n",
    "pruned_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(552.9429, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.abs(pruned_module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc2_module._parameters['weight'] = pruned_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(552.9429, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ok that worked\n",
    "torch.sum(torch.abs(list(fc2_module.named_parameters())[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0572, -0.0000, -0.0000,  ...,  0.0000, -0.0560, -0.0000],\n",
       "        [ 0.0416,  0.0504,  0.0000,  ..., -0.0385, -0.0532, -0.0000],\n",
       "        [ 0.0000, -0.0000, -0.0506,  ..., -0.0000,  0.0000, -0.0556],\n",
       "        ...,\n",
       "        [-0.0000,  0.0000,  0.0502,  ...,  0.0000,  0.0571,  0.0000],\n",
       "        [-0.0543, -0.0424,  0.0000,  ..., -0.0000, -0.0508, -0.0000],\n",
       "        [-0.0448, -0.0000, -0.0421,  ..., -0.0000,  0.0426, -0.0000]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight is now updated \n",
    "torch.sum(torch.abs(fc2_module.weight))\n",
    "fc2_module.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next iterations must be different, only prune non-zero values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False,  ..., False,  True, False],\n",
       "        [ True,  True, False,  ...,  True,  True, False],\n",
       "        [False, False,  True,  ..., False, False,  True],\n",
       "        ...,\n",
       "        [False, False,  True,  ..., False,  True, False],\n",
       "        [ True,  True, False,  ..., False,  True, False],\n",
       "        [ True, False,  True,  ..., False,  True, False]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc2_module.weight != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4800"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nparams_toprune = int(round(0.4 * ((1-0.6) * fc2_module.weight.nelement())))\n",
    "nparams_toprune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<TopkBackward>),\n",
       "indices=tensor([15000,     1,     2,  ...,  4797,  4798,  4799]))"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk = torch.topk(torch.abs(fc2_module.weight).view(-1), k=nparams_toprune, largest=False)\n",
    "topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0572, -0.0000, -0.0000,  ...,  0.0000, -0.0560, -0.0000],\n",
       "        [ 0.0416,  0.0504,  0.0000,  ..., -0.0385, -0.0532, -0.0000],\n",
       "        [ 0.0000, -0.0000, -0.0506,  ..., -0.0000,  0.0000, -0.0556],\n",
       "        ...,\n",
       "        [-0.0000,  0.0000,  0.0502,  ...,  0.0000,  0.0571,  0.0000],\n",
       "        [-0.0543, -0.0424,  0.0000,  ..., -0.0000, -0.0508, -0.0000],\n",
       "        [-0.0448, -0.0000, -0.0421,  ..., -0.0000,  0.0426, -0.0000]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig = fc2_module.weight\n",
    "orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.ones_like(orig)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [1., 1., 0.,  ..., 1., 1., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 1.,  ..., 0., 1., 0.],\n",
       "        [1., 1., 0.,  ..., 0., 1., 0.],\n",
       "        [1., 0., 1.,  ..., 0., 1., 1.]])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.view(-1)[topk.indices] = 0\n",
    "\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(552.9429, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.abs(fc2_module.weight * mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "516.0"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
